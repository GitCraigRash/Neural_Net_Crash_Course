{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitCraigRash/Neural_Net_Crash_Course/blob/main/FirstNuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BACvl52N6YQP"
      },
      "outputs": [],
      "source": [
        "###These import tensorflow and keras. keras is unkown. \n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVMfmXgzSw8-",
        "outputId": "0a44db79-7fbe-4d9b-e0e1-ce1118d5d2a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "###Import data\n",
        "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "train_df = train_df.reindex(np.random.permutation(train_df.index)) # shuffle the examples\n",
        "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3Vleti0TM1G",
        "outputId": "a32b7599-6df3-4718-f090-fea350e351fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17000, 9)\n",
            "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "4942     -118.11     34.18                52.0       3571.0           510.0   \n",
            "16344    -122.51     37.58                20.0         64.0            21.0   \n",
            "15403    -122.30     37.92                33.0       1615.0           271.0   \n",
            "1842     -117.27     33.20                34.0       1852.0           322.0   \n",
            "4063     -117.97     33.68                26.0       3653.0           568.0   \n",
            "\n",
            "       population  households  median_income  median_house_value  \n",
            "4942       1434.0       490.0         5.9009            376000.0  \n",
            "16344        59.0        21.0         2.2375            450000.0  \n",
            "15403       710.0       285.0         4.0804            239000.0  \n",
            "1842        978.0       332.0         4.3542            156900.0  \n",
            "4063       1930.0       585.0         5.7301            260900.0  \n"
          ]
        }
      ],
      "source": [
        "###Examine the data.\n",
        "print(train_df.shape)\n",
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Spit data into trianing set/ training targets and test set/test targets.\n",
        "\n",
        "X_train, X_test, y_train, y_test.train_test_split(train_df,test_df)"
      ],
      "metadata": {
        "id": "isK0e-IIyD1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHAjME_gTD3F"
      },
      "outputs": [],
      "source": [
        "#Uh oh, the numbers in each column are vastly different.\n",
        "\n",
        "#This will mess with the training when it compares 10000s to -100.00s. \n",
        "#What if we could make the numbers closer together, without losing ratio within columns?\n",
        " \n",
        "\n",
        "###Normalize the data.\n",
        "# If you find the average of a column and the standard deviation,\n",
        "# you can subtact the average of the column from its enteries \n",
        "# and divide it by the standard deviation.\n",
        "# The result is smaller numbers, but they maintain the ratios. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean=train_df.mean(axis=0) \n",
        "std=train_df.std(axis=0)\n",
        "train_data=(train_data-mean)/std\n",
        "print(train_data.head())\n",
        "\n",
        "#We normalize the test data, but not by the test data. \n",
        "#Why? \n",
        "#What would happen to the model's testing if we normalized the test set by iteself?\n",
        "\n",
        "test_data= (test_data-mean)/std\n",
        "\n",
        "# We are not supposed to know the mean and std of the test set. \n",
        "# It would artifically improve the model's loss function.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "bsty7s--xNtf",
        "outputId": "01e3cb29-649b-405f-df2c-5ec626670643"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-10f2f670a3f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "rKBSYM_B60mR",
        "outputId": "3306bb67-a28b-4149-d2ca-5b73b6e16b34"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-33cb66d5e056>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    keres.layers.Dense(,activation=tf.nn.relu)# relu changes the results to 1 or 0.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#Example : the simplest possible network.\n",
        "#model= keras.Sequential([keras.layers.Dense(units=1,imput_shape=[1])])\n",
        "\n",
        "#units=1 means a single node.\n",
        "#input_shape=(1) means a single value.\n",
        "\n",
        "model=keras.Sequential([#This is the neural network itself. \n",
        "                        #Sequential groups a linear stack of layers into a tf.keras.Model.\n",
        "    keres.layers.Dense(8,activation='relu', input_shape=(train_model.shape,))# relu changes the top result to 1 others to 0. #import_shape give sthe model weights.\n",
        "    keres.layers.Dense(8,activation='relu'),\n",
        "    keres.layers.Dense(1,)#OutputLayer?\n",
        "])\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sadly,this results in a high variation in the loss fuction for every time the program is run.\n",
        "#Firstly because the training and testing sets are randomly selected each run, and because the small dataset is small.\n",
        "#How can we work around this?\n",
        "#What if we split entire dataset into four parts, trained four seperatly, and average their loss function? \n",
        "#This is k-fold cross validation. \n"
      ],
      "metadata": {
        "id": "cTl1MYBYo45h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=4\n",
        "number_val_examples=train_X.size//k\n",
        "num_epochs=100;#How many times the training runs.\n",
        "all_scores=[]\n",
        "\n",
        "for i in k;\n",
        "  val_data=train_data[i*num_val_examples: (i+1)*num_examples]\n",
        "  val_targets= train_targets[i*num_val_examples: (i+1)*num_val_examples]\n",
        "\n",
        "  partial_train_data  = np.concatenate([train_data[:i*num_val_examples],train_data[(i+1)*num_val_examples:]], axis = 0)\n",
        "  partial_test_targets= np.concatenate([train_targets[:i*num_val_examples],train_data[(i+1)*num_val_examples:]], axis = 0)\n",
        "  \n",
        "  model = build_model()\n",
        "\n",
        "  model.fit(partial_train_data,partial_train_targets,epochs=num_epochs, batch_size=1,verbos=0)\n",
        "  val_mse,val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  all_scores.append(val_mae)\n",
        "# Not sure what most of this is. \n",
        "# It does k-cross val and saves results to all_scores"
      ],
      "metadata": {
        "id": "cuHP3fD0qRaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find the mean absolute error for all k. \n",
        "num_epochs= 200\n",
        "all_mae_histories=[]\n",
        "\n",
        "for i in range(k):\n",
        "  print('processing fold #')"
      ],
      "metadata": {
        "id": "NE2Ks0YS_eF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsQVNa5g78TM"
      },
      "outputs": [],
      "source": [
        "\n",
        "#fit: takes an array of xs and ys and matches them to each other. \n",
        "model.fit(train_images,train_labels,epochs=5)#fitting images to training labels. \n",
        "\n",
        "test_loss,test_acc=model.evaluate(test_images,test_labels)#splits into train and test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKqR9O9sAThV"
      },
      "outputs": [],
      "source": [
        "#Returns y value for given x.\n",
        "#print(model.predict([10.0]))\n",
        "\n",
        "predictions=model.predict(my_images)#returns predictions for new images. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fClpe8jJG8Kt"
      },
      "outputs": [],
      "source": [
        "#Back-Propogation(BP)\n",
        "#Once a training step is complete, your network probably guessed the wrong label(return a high loss function).\n",
        "#A helpful fix is through back-propogation. \n",
        "#BP functions calculate the loss function, then uses that number to change the weights on the last layer.\n",
        "#The weights favoring the desired outcome will be increased and those opposed will be decreased. \n",
        "#Repeat backwards for every layer except the input layer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOCQ2V9sEa_q"
      },
      "outputs": [],
      "source": [
        "#There are multiple types. \n",
        "#BP by simple regression algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKL8y0UMf72B"
      },
      "outputs": [],
      "source": [
        "#a very simple binary classification algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZMKwZgzG8Sz"
      },
      "outputs": [],
      "source": [
        "#Convolutional Nural Networks\n",
        "\n",
        "model = tf.keras.models.Sequential([#creates the model.\n",
        "    tf.keras.layers.Conv2D(64,(3,3),acivation='relu',#generate 64 filters and look for signals.\n",
        "                           input_shape=(28,28,1)),# the number of inputs.\n",
        "    tf.keras.layers.MaxPooling2D(2,2),#reduce the image to find patterns\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),#ditto\n",
        "    tf.keras.layers.MaxPooling2D(2,2),#ditto\n",
        "    tf.keras.layers.Flatten(),#flattens the inputs and while keeping batch size the same. \n",
        "    tf.keras.layers.Dense(128,activation='relu'),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyNVgEP0TxOzdozXeUV6gOyO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}